<div align="center">

# ğŸ”¬ PRism

**See through your pull requests.**

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Node](https://img.shields.io/badge/node-%3E%3D20-brightgreen.svg)](https://nodejs.org)
[![TypeScript](https://img.shields.io/badge/TypeScript-strict-blue.svg)](https://www.typescriptlang.org/)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](CONTRIBUTING.md)

AI-powered pull request reviews that catch bugs, flag security risks, and surface real issues â€” not noise.

</div>

---

## âš¡ 60-Second Setup

```bash
npx prism init
```

That's it. The wizard will:

1. Ask your LLM provider (OpenAI, Anthropic, Ollama, or any OpenAI-compatible endpoint)
2. **Auto-detect available models** and let you pick from a searchable list
3. Generate `prism.config.json` and `.github/workflows/prism.yml`

Then: add your API key as a repo secret, commit, open a PR, and watch PRism review your code.

---

## âœ¨ Features

**ğŸ¤– Multi-Provider Support** â€” OpenAI, Anthropic, Ollama, LM Studio, vLLM, and any `/v1/chat/completions` endpoint.

**ğŸ” Auto-Model Detection** â€” No guessing model names. PRism fetches available models and shows a searchable list during setup.

**ğŸ“Š Structured Reviews** â€” Every review is typed, validated with Zod, and rendered as a clean GitHub comment with risk badges and categorized findings.

**ğŸ¯ Review Profiles** â€” `balanced`, `security`, `performance`, or `strict` â€” tune PRism to what matters for your project.

**ğŸ”‡ Zero Spam** â€” One comment per PR, updated in place. No notification storms, no clutter.

**ğŸ§¹ Noise Filtering** â€” Lockfiles, build artifacts, vendored code, and binaries are automatically skipped. Large diffs are truncated with clear markers.

**ğŸ”’ Secure by Default** â€” Secrets never logged. Uses `pull_request` event (not `pull_request_target`). Defensive validation everywhere.

---

## ğŸ“¸ Demo

<!-- TODO: Add demo GIF showing a PRism review comment on a real PR -->
<!-- ![PRism Review Demo](assets/demo.gif) -->

*Coming soon â€” PRism review on a real pull request.*

---

## ğŸ—ï¸ How It Works

```
PR Opened â†’ GitHub Action Triggers â†’ PRism reads changed files
    â†’ Filters noise â†’ Builds prompt (profile-aware)
    â†’ Calls LLM â†’ Validates response (Zod)
    â†’ Renders Markdown comment â†’ Posts/updates on PR
```

PRism produces a single, high-signal comment with:

- **Risk badge** â€” ğŸŸ¢ Low / ğŸŸ¡ Medium / ğŸ”´ High
- **Findings table** â€” severity, category, location
- **Collapsible details** â€” reasoning and suggestions
- **Praise** â€” good patterns called out

---

## ğŸ”Œ Providers

| Provider | Models API | Chat API | Notes |
|----------|-----------|----------|-------|
| **OpenAI** | `GET /v1/models` | `POST /v1/chat/completions` | Featured models: gpt-4o, o1, o3-mini |
| **Anthropic** | `GET /v1/models` | `POST /v1/messages` | Newest-first sorting, fallback list |
| **OpenAI-compatible** | `GET /v1/models` | `POST /v1/chat/completions` | LM Studio, vLLM, text-gen-webui |
| **Ollama** | `GET /api/tags` | `POST /api/chat` | Local models, recommended picks |

All providers include:
- Retry with exponential backoff + jitter
- Configurable timeouts
- Secret sanitization (keys never logged)
- Graceful fallback if model listing fails

---

## âš™ï¸ Configuration

### `prism.config.json`

```json
{
  "provider": "openai",
  "model": "gpt-4o",
  "apiKeyEnv": "OPENAI_API_KEY",
  "profile": "balanced",
  "commentMode": "summary-only",
  "maxFiles": 30,
  "maxDiffBytes": 100000
}
```

PRism also reads `.prismrc.json` â€” use whichever you prefer.

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `provider` | `openai \| anthropic \| openai-compat \| ollama` | â€” | LLM provider |
| `model` | `string` | â€” | Model identifier |
| `apiKeyEnv` | `string` | â€” | Env var name for the API key |
| `baseUrl` | `string?` | provider default | Custom API base URL |
| `profile` | `balanced \| security \| performance \| strict` | `balanced` | Review focus |
| `commentMode` | `summary-only \| inline+summary` | `summary-only` | Comment style |
| `maxFiles` | `number` | `30` | Max files to review |
| `maxDiffBytes` | `number` | `100000` | Max total diff size |

### Action Inputs

All config fields can be overridden via action inputs:

```yaml
- uses: ./packages/action
  with:
    provider: openai
    model: gpt-4o
    api_key_env: OPENAI_API_KEY
    profile: strict
    config_path: prism.config.json
```

---

## ğŸ”’ Security

- **Secrets**: API keys are read from environment variables, never hardcoded or logged.
- **Event safety**: Uses `pull_request` (not `pull_request_target`) to prevent untrusted code access to secrets.
- **Validation**: All LLM responses are validated with Zod schemas. Invalid responses produce a safe fallback comment.
- **Token scope**: `GITHUB_TOKEN` is used only for reading PR files and posting comments.
- **Rate limiting**: Retry logic respects rate limits with exponential backoff.

See [SECURITY.md](SECURITY.md) for our vulnerability disclosure policy.

---

## ğŸ—ºï¸ Roadmap

- [ ] Inline review comments (file-level annotations)
- [ ] PR description analysis
- [ ] Custom review rules via config
- [ ] Review caching (skip re-reviews for unchanged commits)
- [ ] Dashboard + analytics
- [ ] VS Code extension
- [ ] Support for GitLab and Bitbucket

---

## ğŸ›ï¸ Architecture

```
packages/
â”œâ”€â”€ core/          # Review engine, providers, types, schemas
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ types.ts           # Shared type definitions
â”‚       â”œâ”€â”€ schema.ts          # Zod schemas
â”‚       â”œâ”€â”€ config.ts          # Config loader
â”‚       â”œâ”€â”€ diff.ts            # Diff parser + filter
â”‚       â”œâ”€â”€ prompt.ts          # Prompt builder
â”‚       â”œâ”€â”€ engine.ts          # Review orchestrator
â”‚       â”œâ”€â”€ renderer.ts        # Markdown renderer
â”‚       â”œâ”€â”€ hash.ts            # Cache key utility
â”‚       â””â”€â”€ providers/
â”‚           â”œâ”€â”€ openai.ts
â”‚           â”œâ”€â”€ anthropic.ts
â”‚           â”œâ”€â”€ openai-compat.ts
â”‚           â”œâ”€â”€ ollama.ts
â”‚           â”œâ”€â”€ factory.ts
â”‚           â””â”€â”€ retry.ts
â”œâ”€â”€ cli/           # Interactive setup wizard
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ index.ts
â”‚       â”œâ”€â”€ ui.ts
â”‚       â”œâ”€â”€ commands/
â”‚       â”‚   â”œâ”€â”€ init.ts
â”‚       â”‚   â””â”€â”€ init-prompts.ts
â”‚       â””â”€â”€ generators/
â”‚           â”œâ”€â”€ config.ts
â”‚           â””â”€â”€ workflow.ts
â””â”€â”€ action/        # GitHub Action entry
    â””â”€â”€ src/
        â”œâ”€â”€ index.ts
        â””â”€â”€ github.ts
```

---

## ğŸ¤ Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for development setup, PR guidelines, and code style.

## ğŸ“„ License

[MIT](LICENSE) â€” do whatever you want.
